{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Putting it all together \n",
    "### Associated lectures: All material till lecture 11\n",
    "\n",
    "**See PrairieLearn for _due date_ and _submission_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 4_\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **You may work on this assignment in a group (group size <= 4) and submit your assignment as a group.** \n",
    "- Below are some instructions on working as a group.  \n",
    "    - The maximum group size is 4.\n",
    "    - You can choose your own group members. \n",
    "    - Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "    - Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "    - It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- Be sure to follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2024s/blob/main/docs/homework_instructions.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tests_hw5\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "\n",
    "In this homework you will be working on an open-ended mini-project, where you will put all the different things you have learned so far together to solve an interesting problem.\n",
    "\n",
    "A few notes and tips when you work on this mini-project: \n",
    "\n",
    "#### Tips\n",
    "1. This mini-project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "\n",
    "#### Assessment\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "\n",
    "#### A final note\n",
    "Finally, this style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\". Of course if you're having fun you're welcome to spend as much time as you want! But, if so, try not to do it out of perfectionism or getting the best possible grade. Do it because you're learning and enjoying it. Students from the past cohorts have found such kind of labs useful and fun and I hope you enjoy it as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1. Pick your problem and explain the prediction problem <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 3_\n",
    "\n",
    "In this mini project, you will be working on a classification problem of predicting whether a credit card client will default or not. \n",
    "For this problem, you will use [Default of Credit Card Clients Dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). In this data set, there are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default.payment.next.month\" in the data. The rest of the columns can be used as features. You may take some ideas and compare your results with [the associated research paper](https://www.sciencedirect.com/science/article/pii/S0957417407006719), which is available through [the UBC library](https://www.library.ubc.ca/). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. You can find this information in the documentation on [the dataset page on Kaggle](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). Write a few sentences on your initial thoughts on the problem and the dataset. \n",
    "2. Download the dataset and read it as a pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each feature provides specific information about the client's demographics, credit limit, payment history, and billing amounts. The features in the dataset include demographic details, credit limits, payment history, and billing amounts. Key features are LIMIT_BAL (credit limit), SEX (gender), EDUCATION (education level), MARRIAGE (marital status), AGE (age), PAY_0 to PAY_6 (repayment status for the past 6 months), BILL_AMT1 to BILL_AMT6 (bill statement amounts for the past 6 months), and PAY_AMT1 to PAY_AMT6 (amounts paid in the past 6 months). Features such as LIMIT_BAL, PAY_0 to PAY_6, and BILL_AMT1 to BILL_AMT6 are directly related to the client's financial status and payment history, making them potentially strong predictors of default risk. Demographic features like SEX, EDUCATION, MARRIAGE, and AGE might also play an important role. For example, younger clients or those with less stable marital statuses might have different default rates compared to older or married clients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df = pd.read_csv(\"data/UCI_Credit_Card.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (70%) and test (30%) portions with `random_state=76`.\n",
    "\n",
    "> If your computer cannot handle training on 70% training data, make the test split bigger.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (15000, 24) (15000,)\n",
      "Test set size: (15000, 24) (15000,)\n"
     ]
    }
   ],
   "source": [
    "X = credit_df.drop(columns=['default.payment.next.month'])\n",
    "y = credit_df['default.payment.next.month']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=76)\n",
    "print(\"Training set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set size:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3. EDA <a name=\"3\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. \n",
    "4. Pick appropriate metric/metrics for assessment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.00000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15071.417533</td>\n",
       "      <td>167528.40000</td>\n",
       "      <td>1.601333</td>\n",
       "      <td>1.848533</td>\n",
       "      <td>1.555200</td>\n",
       "      <td>35.416533</td>\n",
       "      <td>-0.011600</td>\n",
       "      <td>-0.135467</td>\n",
       "      <td>-0.165600</td>\n",
       "      <td>-0.218067</td>\n",
       "      <td>...</td>\n",
       "      <td>4.717890e+04</td>\n",
       "      <td>43310.199600</td>\n",
       "      <td>40314.051533</td>\n",
       "      <td>38716.896200</td>\n",
       "      <td>5592.191600</td>\n",
       "      <td>6.189920e+03</td>\n",
       "      <td>5211.853867</td>\n",
       "      <td>4852.437133</td>\n",
       "      <td>4804.635133</td>\n",
       "      <td>5212.562867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8654.862414</td>\n",
       "      <td>129681.73895</td>\n",
       "      <td>0.489640</td>\n",
       "      <td>0.792822</td>\n",
       "      <td>0.520293</td>\n",
       "      <td>9.153510</td>\n",
       "      <td>1.130819</td>\n",
       "      <td>1.199727</td>\n",
       "      <td>1.196051</td>\n",
       "      <td>1.166849</td>\n",
       "      <td>...</td>\n",
       "      <td>7.005481e+04</td>\n",
       "      <td>64018.027468</td>\n",
       "      <td>60415.235032</td>\n",
       "      <td>58915.266417</td>\n",
       "      <td>16033.019708</td>\n",
       "      <td>2.619704e+04</td>\n",
       "      <td>17369.325990</td>\n",
       "      <td>16567.517828</td>\n",
       "      <td>15784.966256</td>\n",
       "      <td>17575.707590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.150600e+04</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-209051.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7559.500000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638750e+03</td>\n",
       "      <td>2349.250000</td>\n",
       "      <td>1774.250000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.270000e+02</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>289.500000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>167.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15149.000000</td>\n",
       "      <td>140000.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.015900e+04</td>\n",
       "      <td>19084.000000</td>\n",
       "      <td>18124.000000</td>\n",
       "      <td>17207.500000</td>\n",
       "      <td>2152.500000</td>\n",
       "      <td>2.010000e+03</td>\n",
       "      <td>1809.500000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22556.750000</td>\n",
       "      <td>240000.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.084325e+04</td>\n",
       "      <td>55420.250000</td>\n",
       "      <td>50526.250000</td>\n",
       "      <td>49267.250000</td>\n",
       "      <td>5025.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4027.750000</td>\n",
       "      <td>4093.250000</td>\n",
       "      <td>4001.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29999.000000</td>\n",
       "      <td>800000.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.664089e+06</td>\n",
       "      <td>706864.000000</td>\n",
       "      <td>823540.000000</td>\n",
       "      <td>527566.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>889043.000000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID     LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
       "count  15000.000000   15000.00000  15000.000000  15000.000000  15000.000000   \n",
       "mean   15071.417533  167528.40000      1.601333      1.848533      1.555200   \n",
       "std     8654.862414  129681.73895      0.489640      0.792822      0.520293   \n",
       "min        4.000000   10000.00000      1.000000      0.000000      0.000000   \n",
       "25%     7559.500000   50000.00000      1.000000      1.000000      1.000000   \n",
       "50%    15149.000000  140000.00000      2.000000      2.000000      2.000000   \n",
       "75%    22556.750000  240000.00000      2.000000      2.000000      2.000000   \n",
       "max    29999.000000  800000.00000      2.000000      6.000000      3.000000   \n",
       "\n",
       "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
       "count  15000.000000  15000.000000  15000.000000  15000.000000  15000.000000   \n",
       "mean      35.416533     -0.011600     -0.135467     -0.165600     -0.218067   \n",
       "std        9.153510      1.130819      1.199727      1.196051      1.166849   \n",
       "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "       ...     BILL_AMT3      BILL_AMT4      BILL_AMT5      BILL_AMT6  \\\n",
       "count  ...  1.500000e+04   15000.000000   15000.000000   15000.000000   \n",
       "mean   ...  4.717890e+04   43310.199600   40314.051533   38716.896200   \n",
       "std    ...  7.005481e+04   64018.027468   60415.235032   58915.266417   \n",
       "min    ... -6.150600e+04 -170000.000000  -81334.000000 -209051.000000   \n",
       "25%    ...  2.638750e+03    2349.250000    1774.250000    1256.000000   \n",
       "50%    ...  2.015900e+04   19084.000000   18124.000000   17207.500000   \n",
       "75%    ...  6.084325e+04   55420.250000   50526.250000   49267.250000   \n",
       "max    ...  1.664089e+06  706864.000000  823540.000000  527566.000000   \n",
       "\n",
       "            PAY_AMT1      PAY_AMT2       PAY_AMT3       PAY_AMT4  \\\n",
       "count   15000.000000  1.500000e+04   15000.000000   15000.000000   \n",
       "mean     5592.191600  6.189920e+03    5211.853867    4852.437133   \n",
       "std     16033.019708  2.619704e+04   17369.325990   16567.517828   \n",
       "min         0.000000  0.000000e+00       0.000000       0.000000   \n",
       "25%      1000.000000  8.270000e+02     390.000000     289.500000   \n",
       "50%      2152.500000  2.010000e+03    1809.500000    1500.000000   \n",
       "75%      5025.000000  5.000000e+03    4600.000000    4027.750000   \n",
       "max    873552.000000  1.684259e+06  889043.000000  621000.000000   \n",
       "\n",
       "            PAY_AMT5       PAY_AMT6  \n",
       "count   15000.000000   15000.000000  \n",
       "mean     4804.635133    5212.562867  \n",
       "std     15784.966256   17575.707590  \n",
       "min         0.000000       0.000000  \n",
       "25%       244.000000     167.750000  \n",
       "50%      1500.000000    1500.000000  \n",
       "75%      4093.250000    4001.250000  \n",
       "max    426529.000000  528666.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = X_train.describe()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEX:\n",
    "- Values: 1 (male), 2 (female)\n",
    "- Mean: 1.60 (skewed towards females)\n",
    "- Standard Deviation: 0.49\n",
    "- Insights: The dataset has more female clients than male clients.\n",
    "\n",
    "PAY_0 to PAY_6 (Repayment Status):\n",
    "- Mean values around -0.01 to -0.22, with standard deviations around 1.12 to 1.20.\n",
    "- Range: -2 to 8\n",
    "- Insights: Most clients do not have significant delays in their repayments. However, there are outliers with repayment statuses up to 8 months late.\n",
    "\n",
    "\n",
    "Observations :\n",
    "The dataset includes clients with a wide range of financial behaviors, from those who consistently pay their bills on time to those who have significant delays.\n",
    "Demographic features such as age, education, and marital status vary but are predominantly focused on educated and middle-aged individuals.\n",
    "The financial features (credit limit, bill amounts, payment amounts) have high variability, suggesting a diverse client base in terms of financial health and behavior.\n",
    "\n",
    "Metrics for Assessment:\n",
    "- Accuracy: To measure the overall correctness of the model.\n",
    "- Precision and Recall: To understand the model's performance on predicting defaults versus non-defaults.\n",
    "- F1-Score: To balance precision and recall.\n",
    "- ROC-AUC: To evaluate the model's ability to discriminate between default and non-default cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 4. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Features:SEX, EDUCATION, MARRIAGE\n",
    "Transformations:Apply one-hot encoding to convert categorical values into binary columns.\n",
    "\n",
    "Numerical Features: LIMIT_BAL, AGE, PAY_0 to PAY_6, BILL_AMT1 to BILL_AMT6, PAY_AMT1 to PAY_AMT6\n",
    "Transformations: Normalize or standardize numerical features to ensure they are on a similar scale.\n",
    "\n",
    "Drop: ID\n",
    "Transformations: Drop the ID column as it does not provide predictive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "numerical_features = ['LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "                      'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "                      'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ])\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.783\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     11745\n",
      "           1       0.00      0.00      0.00      3255\n",
      "\n",
      "    accuracy                           0.78     15000\n",
      "   macro avg       0.39      0.50      0.44     15000\n",
      "weighted avg       0.61      0.78      0.69     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "baseline.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = baseline.predict(X_test_transformed)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 6. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "\n",
    "_points 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try a linear model as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter. \n",
    "3. Report cross-validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Accuracy: 0.8134666666666667\n",
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     11745\n",
      "           1       0.71      0.24      0.36      3255\n",
      "\n",
      "    accuracy                           0.81     15000\n",
      "   macro avg       0.77      0.61      0.62     15000\n",
      "weighted avg       0.80      0.81      0.78     15000\n",
      "\n",
      "Best Parameters: {'C': 100}\n",
      "Cross-Validation Scores: [0.81566667 0.80266667 0.81566667 0.802      0.79966667]\n",
      "Mean CV Score: 0.8071333333333334\n",
      "Standard Deviation of CV Scores: 0.007038307877450212\n",
      "Final Accuracy: 0.8135333333333333\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     11745\n",
      "           1       0.71      0.24      0.36      3255\n",
      "\n",
      "    accuracy                           0.81     15000\n",
      "   macro avg       0.76      0.61      0.62     15000\n",
      "weighted avg       0.80      0.81      0.78     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear = LogisticRegression(solver='liblinear', random_state=76)\n",
    "\n",
    "linear.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = linear.predict(X_test_transformed)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Initial Accuracy: {accuracy}\")\n",
    "print(\"Initial Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(linear, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "\n",
    "best_log_reg = LogisticRegression(solver='liblinear', C=best_params['C'], random_state=76)\n",
    "cv_scores = cross_val_score(best_log_reg, X_train_transformed, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {np.mean(cv_scores)}\")\n",
    "print(f\"Standard Deviation of CV Scores: {np.std(cv_scores)}\")\n",
    "\n",
    "best_log_reg.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_best = best_log_reg.predict(X_test_transformed)\n",
    "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "best_report = classification_report(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Final Accuracy: {best_accuracy}\")\n",
    "print(\"Final Classification Report:\")\n",
    "print(best_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 7. Different models <a name=\"8\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 12_\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try at least 3 other models aside from a linear model. One of these models should be a tree-based ensemble model. \n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_7\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7236\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82     11745\n",
      "           1       0.37      0.41      0.39      3255\n",
      "\n",
      "    accuracy                           0.72     15000\n",
      "   macro avg       0.60      0.61      0.61     15000\n",
      "weighted avg       0.73      0.72      0.73     15000\n",
      "\n",
      "Random Forest Accuracy: 0.8162666666666667\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     11745\n",
      "           1       0.63      0.37      0.47      3255\n",
      "\n",
      "    accuracy                           0.82     15000\n",
      "   macro avg       0.74      0.66      0.68     15000\n",
      "weighted avg       0.80      0.82      0.80     15000\n",
      "\n",
      "SVM Accuracy: 0.813\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     11745\n",
      "           1       0.70      0.24      0.36      3255\n",
      "\n",
      "    accuracy                           0.81     15000\n",
      "   macro avg       0.76      0.61      0.62     15000\n",
      "weighted avg       0.80      0.81      0.78     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=76)\n",
    "\n",
    "tree_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_tree = tree_model.predict(X_test_transformed)\n",
    "\n",
    "tree_accuracy = accuracy_score(y_test, y_pred_tree)\n",
    "tree_report = classification_report(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {tree_accuracy}\")\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(tree_report)\n",
    "\n",
    "\n",
    "forest_model = RandomForestClassifier(random_state=76)\n",
    "\n",
    "forest_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_forest = forest_model.predict(X_test_transformed)\n",
    "\n",
    "forest_accuracy = accuracy_score(y_test, y_pred_forest)\n",
    "forest_report = classification_report(y_test, y_pred_forest)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {forest_accuracy}\")\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(forest_report)\n",
    "\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=76)\n",
    "\n",
    "svm_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test_transformed)\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "svm_report = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the models tested, the Random Forest Classifier performs the best overall, with the highest accuracy and a balanced performance between precision and recall. The linear model (Logistic Regression) also performs well, with good overall metrics and cross-validation scores. The Decision Tree is prone to overfitting, and the SVM shows some underfitting, particularly in recalling the minority class.\n",
    "\n",
    "Therefore, the Random Forest Classifier is recommended as the best model for this task, beating the linear model and the other tested models in terms of overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 8. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_8\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10, 'bootstrap': True}\n",
      "Best Cross-Validation Score for Random Forest: 0.8164666666666667\n",
      "Final Accuracy of Best Random Forest: 0.8224666666666667\n",
      "Final Classification Report of Best Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     11745\n",
      "           1       0.67      0.36      0.47      3255\n",
      "\n",
      "    accuracy                           0.82     15000\n",
      "   macro avg       0.75      0.66      0.68     15000\n",
      "weighted avg       0.81      0.82      0.80     15000\n",
      "\n",
      "Best Parameters for SVM: {'kernel': 'rbf', 'gamma': 'scale', 'C': 1}\n",
      "Best Cross-Validation Score for SVM: 0.8150000000000001\n",
      "Final Accuracy of Best SVM: 0.822\n",
      "Final Classification Report of Best SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     11745\n",
      "           1       0.68      0.35      0.46      3255\n",
      "\n",
      "    accuracy                           0.82     15000\n",
      "   macro avg       0.76      0.65      0.68     15000\n",
      "weighted avg       0.80      0.82      0.80     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#optimization for Forest tree\n",
    "\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=76),\n",
    "                                      param_distributions=param_dist_rf,\n",
    "                                      n_iter=10, \n",
    "                                      cv=5,\n",
    "                                      n_jobs=-1,\n",
    "                                      random_state=76)\n",
    "\n",
    "random_search_rf.fit(X_train_transformed, y_train)\n",
    "\n",
    "best_params_rf = random_search_rf.best_params_\n",
    "best_score_rf = random_search_rf.best_score_\n",
    "\n",
    "print(f\"Best Parameters for Random Forest: {best_params_rf}\")\n",
    "print(f\"Best Cross-Validation Score for Random Forest: {best_score_rf}\")\n",
    "\n",
    "best_rf_model = random_search_rf.best_estimator_\n",
    "y_pred_best_rf = best_rf_model.predict(X_test_transformed)\n",
    "\n",
    "best_rf_accuracy = accuracy_score(y_test, y_pred_best_rf)\n",
    "best_rf_report = classification_report(y_test, y_pred_best_rf)\n",
    "\n",
    "print(f\"Final Accuracy of Best Random Forest: {best_rf_accuracy}\")\n",
    "print(\"Final Classification Report of Best Random Forest:\")\n",
    "print(best_rf_report)\n",
    "\n",
    "#optimising for SVM with ramdomized search \n",
    "param_dist_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search_svm = RandomizedSearchCV(estimator=SVC(random_state=76),\n",
    "                                       param_distributions=param_dist_svm,\n",
    "                                       n_iter=10,\n",
    "                                       cv=5,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=76)\n",
    "\n",
    "random_search_svm.fit(X_train_transformed, y_train)\n",
    "\n",
    "best_params_svm = random_search_svm.best_params_\n",
    "best_score_svm = random_search_svm.best_score_\n",
    "\n",
    "print(f\"Best Parameters for SVM: {best_params_svm}\")\n",
    "print(f\"Best Cross-Validation Score for SVM: {best_score_svm}\")\n",
    "\n",
    "best_svm_model = random_search_svm.best_estimator_\n",
    "y_pred_best_svm = best_svm_model.predict(X_test_transformed)\n",
    "\n",
    "best_svm_accuracy = accuracy_score(y_test, y_pred_best_svm)\n",
    "best_svm_report = classification_report(y_test, y_pred_best_svm)\n",
    "\n",
    "print(f\"Final Accuracy of Best SVM: {best_svm_accuracy}\")\n",
    "print(\"Final Classification Report of Best SVM:\")\n",
    "print(best_svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 9. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data: report and explain test scores.\n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_9\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "The best-performing model, the Random Forest Classifier, achieved an accuracy of 0.8225 on the test set. The classification report shows a precision of 0.84 and recall of 0.95 for Class 0 (non-default), and a precision of 0.67 and recall of 0.36 for Class 1 (default).\n",
    "\n",
    "2. \n",
    "The test score of 0.8225 is very close to the cross-validation score of 0.8147, indicating good generalization. This close agreement suggests that the model is reliable and there is minimal optimization bias. The model's performance on the test set aligns well with the validation results, increasing confidence in its stability and robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10. Summary of results <a name=\"13\"></a>\n",
    "<hr>\n",
    "\n",
    "_points 12_\n",
    "\n",
    "Imagine that you want to present the summary of these results to your boss and co-workers. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a table (printed `DataFrame`) summarizing important results. \n",
    "2. Write concluding remarks.\n",
    "3. Discuss other ideas that you did not try but could potentially improve the performance/interpretability . \n",
    "3. Report your final test score along with the metric you used at the top of this notebook in the [Submission instructions section](#si)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_10\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model                                        Best Params  \\\n",
      "0  Logistic Regression                                         {'C': 0.1}   \n",
      "1        Decision Tree                                            Default   \n",
      "2        Random Forest  {'n_estimators': 200, 'min_samples_split': 2, ...   \n",
      "3                  SVM                                            Default   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0                0.810          0.814  \n",
      "1                0.730          0.730  \n",
      "2                0.817          0.822  \n",
      "3                0.810          0.810  \n"
     ]
    }
   ],
   "source": [
    "summary_data = {\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM'],\n",
    "    'Best Params': [\n",
    "        \"{'C': 0.1}\", \n",
    "        \"Default\", \n",
    "        \"{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10, 'bootstrap': True}\",\n",
    "        \"Default\"\n",
    "    ],\n",
    "    'Validation Accuracy': [0.810, 0.73, 0.817, 0.81],\n",
    "    'Test Accuracy': [0.814, 0.73, 0.822, 0.81]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Concluding Remarks\n",
    "\n",
    "The Random Forest Classifier achieved the highest accuracy on the test set, demonstrating robust performance and good generalization. The close alignment between validation and test scores indicates the model's reliability and minimal optimization bias.\n",
    "\n",
    "3. possible improvements\n",
    "    Feature Engineering: Exploring additional features or transforming existing features could improve model performance.\n",
    "    Ensemble Methods: Combining multiple models using ensemble techniques might enhance predictive power.\n",
    "    Advanced Hyperparameter Tuning: Using Bayesian optimization for more efficient hyperparameter tuning could yield better results.\n",
    "\n",
    "4. Final Score\n",
    "The final test accuracy for the best-performing model, the Random Forest Classifier, is 0.822. This metric was used to evaluate the model's performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using PrairieLearn.\n",
    "4. Make sure that the plots and output are rendered properly in your submitted file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a tricky one but you did it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cpsc330] *",
   "language": "python",
   "name": "conda-env-.conda-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
